{
  "metadata": {
    "created_at": "2025-07-01T11:42:33.096265",
    "version": "1.0.0",
    "description": "RAG System Evaluation Dataset",
    "total_qa_pairs": 12,
    "total_retrieval_tests": 8,
    "total_generation_tests": 6,
    "total_performance_tests": 4,
    "categories": [
      "DevOps",
      "AI/ML",
      "Infrastructure"
    ],
    "difficulty_levels": [
      "intermediate",
      "beginner",
      "advanced"
    ]
  },
  "performance_tests": [
    {
      "test_id": "perf_001",
      "test_type": "latency",
      "description": "Single query response time",
      "query": "What is a large language model?",
      "max_response_time_ms": 5000,
      "target_response_time_ms": 2000
    },
    {
      "test_id": "perf_002",
      "test_type": "throughput",
      "description": "Concurrent query handling",
      "concurrent_queries": 10,
      "queries": [
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?",
        "What is RAG?"
      ],
      "max_total_time_ms": 15000
    },
    {
      "test_id": "perf_003",
      "test_type": "memory_usage",
      "description": "Memory consumption during processing",
      "query": "Explain vector databases and embeddings in detail",
      "max_memory_mb": 1024,
      "baseline_memory_mb": 256
    },
    {
      "test_id": "perf_004",
      "test_type": "scalability",
      "description": "Performance under load",
      "load_levels": [
        1,
        5,
        10,
        20
      ],
      "sample_query": "How does fine-tuning work?",
      "max_degradation_percent": 50
    }
  ]
}